<!DOCTYPE html>
<html>
<head>
  <title>Machine Learning - Data, AI & Machine Learning</title>
  <meta charset="UTF-8">
</head>
<body>

<h1>Machine Learning (ML)</h1>
<p>Machine Learning is a subset of AI that enables systems to learn patterns from data and make predictions or decisions without being explicitly programmed. It relies on statistical models and optimization techniques.</p>

<h2>1. Categories of Machine Learning</h2>
<ul>
  <li><strong>Supervised Learning:</strong> Learn from labeled data (e.g., classification, regression)</li>
  <li><strong>Unsupervised Learning:</strong> Discover structure in unlabeled data (e.g., clustering)</li>
  <li><strong>Semi-Supervised Learning:</strong> Mix of labeled and unlabeled data</li>
  <li><strong>Reinforcement Learning:</strong> Learn by interacting with environment and receiving rewards</li>
</ul>

<h2>2. Supervised Learning Examples</h2>
<pre>
Task: Predict house price
Input: Size, location, number of rooms
Output: Price (regression)

Task: Email classification
Input: Email text
Output: Spam or Not Spam (classification)
</pre>

<h2>3. Unsupervised Learning Examples</h2>
<pre>
Task: Customer segmentation
Input: Purchase history
Output: Clusters of similar customers

Task: Topic modeling
Input: News articles
Output: Grouped by themes
</pre>

<h2>4. Reinforcement Learning Example</h2>
<pre>
Agent: Robot vacuum
Environment: Room layout
Actions: Move, turn, clean
Reward: Cleaned area
Goal: Maximize total reward
</pre>

<h2>5. Common Algorithms</h2>
<table border="1">
  <tr><th>Type</th><th>Algorithm</th><th>Use Case</th></tr>
  <tr><td>Classification</td><td>Logistic Regression</td><td>Binary outcomes</td></tr>
  <tr><td>Classification</td><td>Random Forest</td><td>Multi-class problems</td></tr>
  <tr><td>Regression</td><td>Linear Regression</td><td>Predict continuous values</td></tr>
  <tr><td>Clustering</td><td>K-Means</td><td>Group similar items</td></tr>
  <tr><td>Dimensionality Reduction</td><td>PCA</td><td>Reduce feature space</td></tr>
</table>

<h2>6. ML Workflow</h2>
<ol>
  <li><strong>Data Collection:</strong> Gather relevant data</li>
  <li><strong>Data Cleaning:</strong> Handle missing values, outliers</li>
  <li><strong>Feature Engineering:</strong> Select and transform input variables</li>
  <li><strong>Model Training:</strong> Fit algorithm to data</li>
  <li><strong>Evaluation:</strong> Measure accuracy, precision, recall</li>
  <li><strong>Deployment:</strong> Integrate into production systems</li>
</ol>

<h2>7. Evaluation Metrics</h2>
<ul>
  <li><strong>Accuracy:</strong> Correct predictions / total predictions</li>
  <li><strong>Precision:</strong> True positives / predicted positives</li>
  <li><strong>Recall:</strong> True positives / actual positives</li>
  <li><strong>F1 Score:</strong> Harmonic mean of precision and recall</li>
  <li><strong>ROC-AUC:</strong> Trade-off between true and false positives</li>
</ul>

<h2>8. Tools & Libraries</h2>
<ul>
  <li><strong>scikit-learn:</strong> Classical ML algorithms</li>
  <li><strong>XGBoost:</strong> Gradient boosting framework</li>
  <li><strong>LightGBM:</strong> Fast, efficient boosting</li>
  <li><strong>TensorFlow & PyTorch:</strong> Deep learning support</li>
</ul>

<h2>9. Challenges</h2>
<ul>
  <li><strong>Overfitting:</strong> Model performs well on training but poorly on new data</li>
  <li><strong>Underfitting:</strong> Model fails to capture patterns</li>
  <li><strong>Data Leakage:</strong> Information from test set leaks into training</li>
  <li><strong>Bias:</strong> Skewed predictions due to imbalanced data</li>
</ul>

<h2>10. Applications</h2>
<ul>
  <li><strong>Finance:</strong> Credit scoring, fraud detection</li>
  <li><strong>Healthcare:</strong> Disease prediction, medical imaging</li>
  <li><strong>Retail:</strong> Recommendation engines</li>
  <li><strong>Cybersecurity:</strong> Intrusion detection</li>
</ul>

</body>
</html>
